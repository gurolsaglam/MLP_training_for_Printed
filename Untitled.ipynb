{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "932b67de-2474-4f75-96f0-50728c070a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f392bdb6-95d3-4207-9ee9-349c6b9e18b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a toy dataset for binary classification, 1000 data points with 20 features each\n",
    "X, y = make_classification(1000, 20, n_informative=10, random_state=0)\n",
    "X, y = X.astype(np.float32), y.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62ce3d73-0864-4960-9e6a-c4738346cd42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 20), (1000,), 0.5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape, y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02f74f1-8127-4c82-86da-4ade615a30f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self, \n",
    "                 X_train, X_test, \n",
    "                 y_train, y_test, \n",
    "                 name, \n",
    "                 topology, \n",
    "                 activation='relu', \n",
    "                 max_iter=100):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        self.max_iter = max_iter\n",
    "        self.activation = activation\n",
    "        super(MLP, self).__init__(X_train, X_test, y_train, y_test, name)\n",
    "\n",
    "    def evalAlgo(self):\n",
    "        # print(\"MLPRegressor Regressor w/ Random Parameter Search\")\n",
    "        # mlprS = MLPRegressor(hidden_layer_sizes=self.hidden_layer_sizes, max_iter=self.max_iter)\n",
    "        # param_dists = dict(\n",
    "        # #activation = ['identity', 'logistic', 'tanh', 'relu'],\n",
    "        # solver = ['lbfgs', 'sgd', 'adam'],\n",
    "        # learning_rate = ['constant', 'invscaling', 'adaptive'],\n",
    "        # momentum = uniform(0,1),\n",
    "        # nesterovs_momentum = [True, False],\n",
    "        # validation_fraction = uniform(0,1),\n",
    "        # beta_1 = uniform(0,0.999),\n",
    "        # beta_2 = uniform(0,0.999),\n",
    "        # epsilon = uniform(0,0.999)\n",
    "        # )\n",
    "        # bmodel=self.searchAndEvalRegressor(mlprS,param_dists)\n",
    "        # print('**** Regressor ****')\n",
    "        # #print('weights: ', bmodel.coefs_)\n",
    "        # #print('intercepts: ', bmodel.intercepts_)\n",
    "        # #print('act: ', bmodel.activation)\n",
    "        # #print('outact: ', bmodel.out_activation_)\n",
    "\n",
    "        # print(\"\")\n",
    "        # print(\"MLPRegressor w/o Random Parameter Search\")\n",
    "        # mlpr0 = MLPRegressor(hidden_layer_sizes=self.hidden_layer_sizes, max_iter=self.max_iter)\n",
    "        # self.evalRegressor(mlpr0)\n",
    "\n",
    "        # print(\"\")\n",
    "\n",
    "        print(\"MLP w/o Random Parameter Search\")\n",
    "        mlpc0 = MLPClassifier(hidden_layer_sizes=self.hidden_layer_sizes, max_iter=self.max_iter)\n",
    "        self.evalClassifier(mlpc0)\n",
    "        print(\"MLP w/ Random Parameter Search\")\n",
    "        mlpcS = MLPClassifier(hidden_layer_sizes=self.hidden_layer_sizes, max_iter=self.max_iter)\n",
    "        param_dists = dict(\n",
    "            # activation = ['identity', 'logistic', 'tanh', 'relu'],\n",
    "            solver=['lbfgs', 'sgd', 'adam'],\n",
    "            learning_rate=['constant', 'invscaling', 'adaptive'],\n",
    "            momentum=uniform(0, 1),\n",
    "            nesterovs_momentum=[True, False],\n",
    "            validation_fraction=uniform(0, 1),\n",
    "            beta_1=uniform(0, 0.999),\n",
    "            beta_2=uniform(0, 0.999),\n",
    "            epsilon=uniform(0, 0.999)\n",
    "        )\n",
    "        bmodel, params, accuracy = self.searchAndEvalClassifier(mlpcS, param_dists)\n",
    "        return bmodel, params, accuracy\n",
    "\n",
    "    def evalClassifier(self, clf):\n",
    "        np.set_printoptions(threshold=np.inf)\n",
    "        search = clf.fit(self.X_train, self.y_train)\n",
    "        pred = clf.predict(self.X_test)\n",
    "\n",
    "        print(\"mean squared error: \", mean_squared_error(pred, self.y_test))\n",
    "        print(\"accuracy score: \", accuracy_score(pred, self.y_test))\n",
    "        print(classification_report(self.y_test, pred))\n",
    "        bmodel = clf\n",
    "        return pred\n",
    "\n",
    "    def searchAndEvalClassifier(self, clf, param_dists):\n",
    "        classifier = RandomizedSearchCV(clf, param_dists, random_state=0, cv=5, n_iter=600, n_jobs=self.njobs)\n",
    "        # classifier = GridSearchCV(dt, param_dists, scoring='f1_micro', cv=5)\n",
    "\n",
    "        search = classifier.fit(self.X_train, self.y_train)\n",
    "        pred = classifier.predict(self.X_test)\n",
    "\n",
    "        print(\"best parameters found: \", search.best_params_)\n",
    "        print(\"mean squared error: \", mean_squared_error(pred, self.y_test))\n",
    "        print(\"accuracy score: \", accuracy_score(pred, self.y_test))\n",
    "        print(classification_report(self.y_test, pred))\n",
    "\n",
    "        dummy = DummyClassifier(strategy='most_frequent').fit(self.X_train, self.y_train)\n",
    "        print(\"Baseline_Accuracy: {}\".format(accuracy_score(dummy.predict(self.X_test), self.y_test)))\n",
    "        # print('**** Classifier ****')\n",
    "        bmodel = classifier.best_estimator_\n",
    "\n",
    "        pred = bmodel.predict(self.X_test)\n",
    "        accuracy = accuracy_score(pred, self.y_test)\n",
    "        print(\"accuracy score: \", accuracy)\n",
    "        return bmodel, search.best_params_, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25a613be-9db2-4bd3-91a5-f4afa2245308",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_units=10,\n",
    "            nonlin=F.relu,\n",
    "            dropout=0.5,\n",
    "    ):\n",
    "        super(MLP, self).__init__()\n",
    "        self.num_units = num_units\n",
    "        self.nonlin = nonlin\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.dense0 = nn.Linear(20, num_units)\n",
    "        self.nonlin = nonlin\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.dense1 = nn.Linear(num_units, 10)\n",
    "        self.output = nn.Linear(10, 2)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = self.nonlin(self.dense0(X))\n",
    "        X = self.dropout(X)\n",
    "        X = F.relu(self.dense1(X))\n",
    "        X = F.softmax(self.output(X), dim=-1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b20a27d-5792-428a-8bcb-3ae24164b62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch import NeuralNetClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c5d1757-7e95-4111-8afe-e3d9ed51431d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom optimizer to encapsulate Adam\n",
    "def make_lookahead(parameters, optimizer_cls, k, alpha, **kwargs):\n",
    "    optimizer = optimizer_cls(parameters, **kwargs)\n",
    "    return Lookahead(optimizer=optimizer, k=k, alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3b3b89ae-db47-4f9e-90c6-ae4b03e62537",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    MLP,\n",
    "    max_epochs=20,\n",
    "    # lr=0.1,\n",
    "    criterion=torch.nn.NLLLoss,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    optimizer__lr=1e-3,\n",
    "    optimizer__weight_decay=1e-2,\n",
    "#     device='cuda',  # uncomment this to train with CUDA\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c8f1f94e-63d9-448d-b680-b65f01973b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6903\u001b[0m       \u001b[32m0.5250\u001b[0m        \u001b[35m0.6838\u001b[0m  0.0430\n",
      "      2        \u001b[36m0.6831\u001b[0m       \u001b[32m0.5300\u001b[0m        \u001b[35m0.6814\u001b[0m  0.0387\n",
      "      3        \u001b[36m0.6795\u001b[0m       \u001b[32m0.5550\u001b[0m        \u001b[35m0.6788\u001b[0m  0.0368\n",
      "      4        \u001b[36m0.6751\u001b[0m       \u001b[32m0.5800\u001b[0m        \u001b[35m0.6758\u001b[0m  0.0301\n",
      "      5        \u001b[36m0.6723\u001b[0m       0.5550        \u001b[35m0.6723\u001b[0m  0.0324\n",
      "      6        \u001b[36m0.6639\u001b[0m       \u001b[32m0.6000\u001b[0m        \u001b[35m0.6684\u001b[0m  0.0335\n",
      "      7        \u001b[36m0.6612\u001b[0m       \u001b[32m0.6100\u001b[0m        \u001b[35m0.6642\u001b[0m  0.0329\n",
      "      8        \u001b[36m0.6534\u001b[0m       \u001b[32m0.6350\u001b[0m        \u001b[35m0.6596\u001b[0m  0.0389\n",
      "      9        \u001b[36m0.6525\u001b[0m       \u001b[32m0.6550\u001b[0m        \u001b[35m0.6545\u001b[0m  0.0423\n",
      "     10        \u001b[36m0.6453\u001b[0m       \u001b[32m0.6650\u001b[0m        \u001b[35m0.6489\u001b[0m  0.0361\n",
      "     11        0.6481       \u001b[32m0.6800\u001b[0m        \u001b[35m0.6431\u001b[0m  0.0321\n",
      "     12        \u001b[36m0.6401\u001b[0m       0.6800        \u001b[35m0.6377\u001b[0m  0.0323\n",
      "     13        \u001b[36m0.6279\u001b[0m       \u001b[32m0.6900\u001b[0m        \u001b[35m0.6321\u001b[0m  0.0341\n",
      "     14        \u001b[36m0.6115\u001b[0m       \u001b[32m0.6950\u001b[0m        \u001b[35m0.6257\u001b[0m  0.0364\n",
      "     15        \u001b[36m0.6094\u001b[0m       0.6950        \u001b[35m0.6189\u001b[0m  0.0359\n",
      "     16        \u001b[36m0.6017\u001b[0m       0.6950        \u001b[35m0.6119\u001b[0m  0.0332\n",
      "     17        \u001b[36m0.5821\u001b[0m       \u001b[32m0.7050\u001b[0m        \u001b[35m0.6038\u001b[0m  0.0360\n",
      "     18        0.5910       \u001b[32m0.7150\u001b[0m        \u001b[35m0.5969\u001b[0m  0.0343\n",
      "     19        \u001b[36m0.5738\u001b[0m       0.7150        \u001b[35m0.5911\u001b[0m  0.0348\n",
      "     20        \u001b[36m0.5695\u001b[0m       \u001b[32m0.7250\u001b[0m        \u001b[35m0.5863\u001b[0m  0.0918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=MLP(\n",
       "    (dense0): Linear(in_features=20, out_features=10, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (dense1): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (output): Linear(in_features=10, out_features=2, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the network\n",
    "net.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "93c68152-c20c-4fbd-bcbe-95360a293ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca106d15-b0ff-4757-8f07-9ef3d0dfc0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'lr': [0.05, 0.1],\n",
    "    'module__num_units': [10, 20],\n",
    "    'module__dropout': [0, 0.5],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6eb87f3c-d97a-4e47-acd7-3df81393281c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(net, params, refit=False, cv=3, scoring='accuracy', verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bb273201-e4a8-48bb-b0e0-15fa59593518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7032\u001b[0m       \u001b[32m0.4851\u001b[0m        \u001b[35m0.7007\u001b[0m  0.0319\n",
      "      2        \u001b[36m0.6940\u001b[0m       \u001b[32m0.4925\u001b[0m        \u001b[35m0.6939\u001b[0m  0.0250\n",
      "      3        \u001b[36m0.6861\u001b[0m       \u001b[32m0.5299\u001b[0m        \u001b[35m0.6875\u001b[0m  0.0190\n",
      "      4        \u001b[36m0.6789\u001b[0m       \u001b[32m0.5821\u001b[0m        \u001b[35m0.6815\u001b[0m  0.0288\n",
      "      5        \u001b[36m0.6718\u001b[0m       \u001b[32m0.6194\u001b[0m        \u001b[35m0.6756\u001b[0m  0.0221\n",
      "      6        \u001b[36m0.6647\u001b[0m       \u001b[32m0.6269\u001b[0m        \u001b[35m0.6694\u001b[0m  0.0207\n",
      "      7        \u001b[36m0.6576\u001b[0m       0.6269        \u001b[35m0.6630\u001b[0m  0.0243\n",
      "      8        \u001b[36m0.6502\u001b[0m       \u001b[32m0.6343\u001b[0m        \u001b[35m0.6564\u001b[0m  0.0228\n",
      "      9        \u001b[36m0.6426\u001b[0m       0.6343        \u001b[35m0.6496\u001b[0m  0.0212\n",
      "     10        \u001b[36m0.6346\u001b[0m       \u001b[32m0.6642\u001b[0m        \u001b[35m0.6424\u001b[0m  0.0266\n",
      "     11        \u001b[36m0.6261\u001b[0m       \u001b[32m0.7090\u001b[0m        \u001b[35m0.6344\u001b[0m  0.0249\n",
      "     12        \u001b[36m0.6171\u001b[0m       \u001b[32m0.7164\u001b[0m        \u001b[35m0.6258\u001b[0m  0.0233\n",
      "     13        \u001b[36m0.6076\u001b[0m       \u001b[32m0.7239\u001b[0m        \u001b[35m0.6169\u001b[0m  0.0228\n",
      "     14        \u001b[36m0.5977\u001b[0m       \u001b[32m0.7313\u001b[0m        \u001b[35m0.6078\u001b[0m  0.0530\n",
      "     15        \u001b[36m0.5875\u001b[0m       0.7164        \u001b[35m0.5985\u001b[0m  0.0287\n",
      "     16        \u001b[36m0.5770\u001b[0m       \u001b[32m0.7388\u001b[0m        \u001b[35m0.5892\u001b[0m  0.0196\n",
      "     17        \u001b[36m0.5664\u001b[0m       0.7313        \u001b[35m0.5799\u001b[0m  0.0239\n",
      "     18        \u001b[36m0.5558\u001b[0m       0.7388        \u001b[35m0.5709\u001b[0m  0.0218\n",
      "     19        \u001b[36m0.5454\u001b[0m       0.7313        \u001b[35m0.5623\u001b[0m  0.0235\n",
      "     20        \u001b[36m0.5353\u001b[0m       0.7388        \u001b[35m0.5542\u001b[0m  0.0269\n",
      "[CV] END ...lr=0.05, module__dropout=0, module__num_units=10; total time=   0.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7287\u001b[0m       \u001b[32m0.4925\u001b[0m        \u001b[35m0.7162\u001b[0m  0.0238\n",
      "      2        \u001b[36m0.7183\u001b[0m       0.4925        \u001b[35m0.7100\u001b[0m  0.0231\n",
      "      3        \u001b[36m0.7103\u001b[0m       \u001b[32m0.5075\u001b[0m        \u001b[35m0.7049\u001b[0m  0.0267\n",
      "      4        \u001b[36m0.7038\u001b[0m       \u001b[32m0.5149\u001b[0m        \u001b[35m0.7003\u001b[0m  0.0252\n",
      "      5        \u001b[36m0.6987\u001b[0m       0.5075        \u001b[35m0.6964\u001b[0m  0.0247\n",
      "      6        \u001b[36m0.6944\u001b[0m       0.5149        \u001b[35m0.6927\u001b[0m  0.0344\n",
      "      7        \u001b[36m0.6905\u001b[0m       \u001b[32m0.5224\u001b[0m        \u001b[35m0.6893\u001b[0m  0.0230\n",
      "      8        \u001b[36m0.6869\u001b[0m       \u001b[32m0.5299\u001b[0m        \u001b[35m0.6862\u001b[0m  0.0254\n",
      "      9        \u001b[36m0.6833\u001b[0m       0.5224        \u001b[35m0.6832\u001b[0m  0.0251\n",
      "     10        \u001b[36m0.6796\u001b[0m       0.5075        \u001b[35m0.6801\u001b[0m  0.0255\n",
      "     11        \u001b[36m0.6757\u001b[0m       0.5149        \u001b[35m0.6768\u001b[0m  0.0260\n",
      "     12        \u001b[36m0.6714\u001b[0m       0.5149        \u001b[35m0.6730\u001b[0m  0.0258\n",
      "     13        \u001b[36m0.6668\u001b[0m       0.5224        \u001b[35m0.6690\u001b[0m  0.0236\n",
      "     14        \u001b[36m0.6620\u001b[0m       \u001b[32m0.5522\u001b[0m        \u001b[35m0.6649\u001b[0m  0.0742\n",
      "     15        \u001b[36m0.6571\u001b[0m       0.5448        \u001b[35m0.6607\u001b[0m  0.0353\n",
      "     16        \u001b[36m0.6518\u001b[0m       0.5448        \u001b[35m0.6565\u001b[0m  0.0234\n",
      "     17        \u001b[36m0.6462\u001b[0m       0.5448        \u001b[35m0.6522\u001b[0m  0.0262\n",
      "     18        \u001b[36m0.6403\u001b[0m       \u001b[32m0.5597\u001b[0m        \u001b[35m0.6476\u001b[0m  0.0231\n",
      "     19        \u001b[36m0.6340\u001b[0m       \u001b[32m0.5672\u001b[0m        \u001b[35m0.6428\u001b[0m  0.0282\n",
      "     20        \u001b[36m0.6272\u001b[0m       0.5597        \u001b[35m0.6379\u001b[0m  0.0327\n",
      "[CV] END ...lr=0.05, module__dropout=0, module__num_units=10; total time=   0.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7196\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7147\u001b[0m  0.0260\n",
      "      2        \u001b[36m0.7123\u001b[0m       0.5000        \u001b[35m0.7112\u001b[0m  0.0276\n",
      "      3        \u001b[36m0.7074\u001b[0m       0.5000        \u001b[35m0.7083\u001b[0m  0.0280\n",
      "      4        \u001b[36m0.7030\u001b[0m       0.5000        \u001b[35m0.7057\u001b[0m  0.0261\n",
      "      5        \u001b[36m0.6990\u001b[0m       0.5000        \u001b[35m0.7033\u001b[0m  0.0280\n",
      "      6        \u001b[36m0.6952\u001b[0m       0.5000        \u001b[35m0.7011\u001b[0m  0.0244\n",
      "      7        \u001b[36m0.6915\u001b[0m       0.5000        \u001b[35m0.6990\u001b[0m  0.0288\n",
      "      8        \u001b[36m0.6879\u001b[0m       0.5000        \u001b[35m0.6972\u001b[0m  0.0258\n",
      "      9        \u001b[36m0.6842\u001b[0m       0.5000        \u001b[35m0.6953\u001b[0m  0.0289\n",
      "     10        \u001b[36m0.6806\u001b[0m       0.5000        \u001b[35m0.6935\u001b[0m  0.0257\n",
      "     11        \u001b[36m0.6767\u001b[0m       0.5000        \u001b[35m0.6916\u001b[0m  0.0262\n",
      "     12        \u001b[36m0.6727\u001b[0m       0.5000        \u001b[35m0.6895\u001b[0m  0.0242\n",
      "     13        \u001b[36m0.6684\u001b[0m       0.5000        \u001b[35m0.6873\u001b[0m  0.0238\n",
      "     14        \u001b[36m0.6637\u001b[0m       \u001b[32m0.5075\u001b[0m        \u001b[35m0.6848\u001b[0m  0.0225\n",
      "     15        \u001b[36m0.6585\u001b[0m       \u001b[32m0.5299\u001b[0m        \u001b[35m0.6821\u001b[0m  0.0270\n",
      "     16        \u001b[36m0.6529\u001b[0m       \u001b[32m0.5522\u001b[0m        \u001b[35m0.6790\u001b[0m  0.0257\n",
      "     17        \u001b[36m0.6466\u001b[0m       \u001b[32m0.5597\u001b[0m        \u001b[35m0.6753\u001b[0m  0.0259\n",
      "     18        \u001b[36m0.6395\u001b[0m       \u001b[32m0.5896\u001b[0m        \u001b[35m0.6706\u001b[0m  0.0243\n",
      "     19        \u001b[36m0.6318\u001b[0m       \u001b[32m0.6269\u001b[0m        \u001b[35m0.6650\u001b[0m  0.0252\n",
      "     20        \u001b[36m0.6234\u001b[0m       \u001b[32m0.6493\u001b[0m        \u001b[35m0.6589\u001b[0m  0.0231\n",
      "[CV] END ...lr=0.05, module__dropout=0, module__num_units=10; total time=   0.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7018\u001b[0m       \u001b[32m0.5149\u001b[0m        \u001b[35m0.6964\u001b[0m  0.0204\n",
      "      2        \u001b[36m0.6931\u001b[0m       0.5075        \u001b[35m0.6901\u001b[0m  0.0213\n",
      "      3        \u001b[36m0.6855\u001b[0m       \u001b[32m0.5224\u001b[0m        \u001b[35m0.6839\u001b[0m  0.0246\n",
      "      4        \u001b[36m0.6783\u001b[0m       \u001b[32m0.5746\u001b[0m        \u001b[35m0.6779\u001b[0m  0.0199\n",
      "      5        \u001b[36m0.6712\u001b[0m       \u001b[32m0.6493\u001b[0m        \u001b[35m0.6717\u001b[0m  0.0257\n",
      "      6        \u001b[36m0.6639\u001b[0m       \u001b[32m0.6642\u001b[0m        \u001b[35m0.6653\u001b[0m  0.0222\n",
      "      7        \u001b[36m0.6562\u001b[0m       \u001b[32m0.6940\u001b[0m        \u001b[35m0.6587\u001b[0m  0.0219\n",
      "      8        \u001b[36m0.6481\u001b[0m       \u001b[32m0.7090\u001b[0m        \u001b[35m0.6517\u001b[0m  0.0220\n",
      "      9        \u001b[36m0.6395\u001b[0m       \u001b[32m0.7313\u001b[0m        \u001b[35m0.6442\u001b[0m  0.0206\n",
      "     10        \u001b[36m0.6304\u001b[0m       0.7313        \u001b[35m0.6363\u001b[0m  0.0218\n",
      "     11        \u001b[36m0.6207\u001b[0m       \u001b[32m0.7463\u001b[0m        \u001b[35m0.6278\u001b[0m  0.0236\n",
      "     12        \u001b[36m0.6107\u001b[0m       \u001b[32m0.7537\u001b[0m        \u001b[35m0.6189\u001b[0m  0.0239\n",
      "     13        \u001b[36m0.6001\u001b[0m       0.7537        \u001b[35m0.6100\u001b[0m  0.0228\n",
      "     14        \u001b[36m0.5892\u001b[0m       \u001b[32m0.7687\u001b[0m        \u001b[35m0.6007\u001b[0m  0.0676\n",
      "     15        \u001b[36m0.5778\u001b[0m       \u001b[32m0.7761\u001b[0m        \u001b[35m0.5913\u001b[0m  0.0306\n",
      "     16        \u001b[36m0.5663\u001b[0m       \u001b[32m0.7910\u001b[0m        \u001b[35m0.5819\u001b[0m  0.0271\n",
      "     17        \u001b[36m0.5545\u001b[0m       0.7910        \u001b[35m0.5725\u001b[0m  0.0242\n",
      "     18        \u001b[36m0.5426\u001b[0m       \u001b[32m0.7985\u001b[0m        \u001b[35m0.5633\u001b[0m  0.0235\n",
      "     19        \u001b[36m0.5307\u001b[0m       \u001b[32m0.8060\u001b[0m        \u001b[35m0.5543\u001b[0m  0.0266\n",
      "     20        \u001b[36m0.5189\u001b[0m       0.8060        \u001b[35m0.5457\u001b[0m  0.0223\n",
      "[CV] END ...lr=0.05, module__dropout=0, module__num_units=20; total time=   0.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6985\u001b[0m       \u001b[32m0.5149\u001b[0m        \u001b[35m0.7035\u001b[0m  0.0224\n",
      "      2        \u001b[36m0.6900\u001b[0m       \u001b[32m0.5448\u001b[0m        \u001b[35m0.6978\u001b[0m  0.0225\n",
      "      3        \u001b[36m0.6826\u001b[0m       \u001b[32m0.5522\u001b[0m        \u001b[35m0.6925\u001b[0m  0.0202\n",
      "      4        \u001b[36m0.6756\u001b[0m       0.5373        \u001b[35m0.6879\u001b[0m  0.0243\n",
      "      5        \u001b[36m0.6693\u001b[0m       0.5448        \u001b[35m0.6833\u001b[0m  0.0242\n",
      "      6        \u001b[36m0.6631\u001b[0m       \u001b[32m0.5672\u001b[0m        \u001b[35m0.6790\u001b[0m  0.0237\n",
      "      7        \u001b[36m0.6568\u001b[0m       \u001b[32m0.5821\u001b[0m        \u001b[35m0.6749\u001b[0m  0.0268\n",
      "      8        \u001b[36m0.6503\u001b[0m       0.5597        \u001b[35m0.6709\u001b[0m  0.0229\n",
      "      9        \u001b[36m0.6435\u001b[0m       \u001b[32m0.5896\u001b[0m        \u001b[35m0.6671\u001b[0m  0.0253\n",
      "     10        \u001b[36m0.6362\u001b[0m       \u001b[32m0.6045\u001b[0m        \u001b[35m0.6629\u001b[0m  0.0276\n",
      "     11        \u001b[36m0.6285\u001b[0m       \u001b[32m0.6194\u001b[0m        \u001b[35m0.6582\u001b[0m  0.0226\n",
      "     12        \u001b[36m0.6201\u001b[0m       \u001b[32m0.6418\u001b[0m        \u001b[35m0.6532\u001b[0m  0.0218\n",
      "     13        \u001b[36m0.6112\u001b[0m       \u001b[32m0.6493\u001b[0m        \u001b[35m0.6477\u001b[0m  0.0284\n",
      "     14        \u001b[36m0.6017\u001b[0m       0.6493        \u001b[35m0.6418\u001b[0m  0.0241\n",
      "     15        \u001b[36m0.5913\u001b[0m       0.6493        \u001b[35m0.6359\u001b[0m  0.0241\n",
      "     16        \u001b[36m0.5807\u001b[0m       \u001b[32m0.6567\u001b[0m        \u001b[35m0.6293\u001b[0m  0.0258\n",
      "     17        \u001b[36m0.5699\u001b[0m       0.6567        \u001b[35m0.6222\u001b[0m  0.0209\n",
      "     18        \u001b[36m0.5593\u001b[0m       0.6567        \u001b[35m0.6150\u001b[0m  0.0225\n",
      "     19        \u001b[36m0.5486\u001b[0m       0.6567        \u001b[35m0.6077\u001b[0m  0.0200\n",
      "     20        \u001b[36m0.5378\u001b[0m       0.6418        \u001b[35m0.6006\u001b[0m  0.0236\n",
      "[CV] END ...lr=0.05, module__dropout=0, module__num_units=20; total time=   0.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7081\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7074\u001b[0m  0.0220\n",
      "      2        \u001b[36m0.7035\u001b[0m       0.5000        \u001b[35m0.7059\u001b[0m  0.0225\n",
      "      3        \u001b[36m0.7006\u001b[0m       0.5000        \u001b[35m0.7046\u001b[0m  0.0240\n",
      "      4        \u001b[36m0.6980\u001b[0m       0.5000        \u001b[35m0.7033\u001b[0m  0.0224\n",
      "      5        \u001b[36m0.6955\u001b[0m       0.5000        \u001b[35m0.7018\u001b[0m  0.0225\n",
      "      6        \u001b[36m0.6928\u001b[0m       0.5000        \u001b[35m0.7000\u001b[0m  0.0260\n",
      "      7        \u001b[36m0.6898\u001b[0m       0.5000        \u001b[35m0.6978\u001b[0m  0.0269\n",
      "      8        \u001b[36m0.6866\u001b[0m       \u001b[32m0.5075\u001b[0m        \u001b[35m0.6956\u001b[0m  0.0230\n",
      "      9        \u001b[36m0.6828\u001b[0m       \u001b[32m0.5149\u001b[0m        \u001b[35m0.6931\u001b[0m  0.0242\n",
      "     10        \u001b[36m0.6784\u001b[0m       \u001b[32m0.5224\u001b[0m        \u001b[35m0.6899\u001b[0m  0.0257\n",
      "     11        \u001b[36m0.6732\u001b[0m       \u001b[32m0.5373\u001b[0m        \u001b[35m0.6859\u001b[0m  0.0243\n",
      "     12        \u001b[36m0.6672\u001b[0m       \u001b[32m0.5672\u001b[0m        \u001b[35m0.6809\u001b[0m  0.0217\n",
      "     13        \u001b[36m0.6600\u001b[0m       0.5672        \u001b[35m0.6753\u001b[0m  0.0256\n",
      "     14        \u001b[36m0.6519\u001b[0m       \u001b[32m0.5821\u001b[0m        \u001b[35m0.6693\u001b[0m  0.0272\n",
      "     15        \u001b[36m0.6427\u001b[0m       \u001b[32m0.6045\u001b[0m        \u001b[35m0.6629\u001b[0m  0.0258\n",
      "     16        \u001b[36m0.6324\u001b[0m       \u001b[32m0.6119\u001b[0m        \u001b[35m0.6561\u001b[0m  0.0220\n",
      "     17        \u001b[36m0.6216\u001b[0m       \u001b[32m0.6343\u001b[0m        \u001b[35m0.6494\u001b[0m  0.0207\n",
      "     18        \u001b[36m0.6104\u001b[0m       \u001b[32m0.6418\u001b[0m        \u001b[35m0.6427\u001b[0m  0.0209\n",
      "     19        \u001b[36m0.5987\u001b[0m       0.6418        \u001b[35m0.6360\u001b[0m  0.0244\n",
      "     20        \u001b[36m0.5869\u001b[0m       0.6418        \u001b[35m0.6293\u001b[0m  0.0241\n",
      "[CV] END ...lr=0.05, module__dropout=0, module__num_units=20; total time=   0.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7106\u001b[0m       \u001b[32m0.5149\u001b[0m        \u001b[35m0.6998\u001b[0m  0.0189\n",
      "      2        \u001b[36m0.7001\u001b[0m       \u001b[32m0.5299\u001b[0m        \u001b[35m0.6965\u001b[0m  0.0228\n",
      "      3        0.7013       \u001b[32m0.5373\u001b[0m        \u001b[35m0.6933\u001b[0m  0.0233\n",
      "      4        \u001b[36m0.6950\u001b[0m       \u001b[32m0.5448\u001b[0m        \u001b[35m0.6906\u001b[0m  0.0226\n",
      "      5        \u001b[36m0.6915\u001b[0m       \u001b[32m0.5672\u001b[0m        \u001b[35m0.6882\u001b[0m  0.0235\n",
      "      6        \u001b[36m0.6899\u001b[0m       \u001b[32m0.5746\u001b[0m        \u001b[35m0.6859\u001b[0m  0.0240\n",
      "      7        \u001b[36m0.6898\u001b[0m       \u001b[32m0.6045\u001b[0m        \u001b[35m0.6836\u001b[0m  0.0229\n",
      "      8        \u001b[36m0.6851\u001b[0m       \u001b[32m0.6194\u001b[0m        \u001b[35m0.6813\u001b[0m  0.0674\n",
      "      9        \u001b[36m0.6784\u001b[0m       0.6194        \u001b[35m0.6790\u001b[0m  0.0293\n",
      "     10        \u001b[36m0.6708\u001b[0m       \u001b[32m0.6269\u001b[0m        \u001b[35m0.6762\u001b[0m  0.0238\n",
      "     11        0.6733       \u001b[32m0.6567\u001b[0m        \u001b[35m0.6730\u001b[0m  0.0238\n",
      "     12        0.6774       \u001b[32m0.6866\u001b[0m        \u001b[35m0.6698\u001b[0m  0.0249\n",
      "     13        0.6757       \u001b[32m0.7239\u001b[0m        \u001b[35m0.6665\u001b[0m  0.0225\n",
      "     14        \u001b[36m0.6685\u001b[0m       \u001b[32m0.7388\u001b[0m        \u001b[35m0.6631\u001b[0m  0.0251\n",
      "     15        \u001b[36m0.6621\u001b[0m       \u001b[32m0.7537\u001b[0m        \u001b[35m0.6594\u001b[0m  0.0266\n",
      "     16        \u001b[36m0.6597\u001b[0m       \u001b[32m0.7687\u001b[0m        \u001b[35m0.6552\u001b[0m  0.0255\n",
      "     17        0.6602       0.7612        \u001b[35m0.6507\u001b[0m  0.0286\n",
      "     18        \u001b[36m0.6449\u001b[0m       0.7687        \u001b[35m0.6456\u001b[0m  0.0278\n",
      "     19        \u001b[36m0.6392\u001b[0m       0.7612        \u001b[35m0.6401\u001b[0m  0.0395\n",
      "     20        \u001b[36m0.6378\u001b[0m       0.7612        \u001b[35m0.6346\u001b[0m  0.0395\n",
      "[CV] END .lr=0.05, module__dropout=0.5, module__num_units=10; total time=   0.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7104\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7036\u001b[0m  0.0367\n",
      "      2        \u001b[36m0.7098\u001b[0m       \u001b[32m0.5373\u001b[0m        \u001b[35m0.6981\u001b[0m  0.0301\n",
      "      3        \u001b[36m0.6970\u001b[0m       \u001b[32m0.5821\u001b[0m        \u001b[35m0.6933\u001b[0m  0.0286\n",
      "      4        \u001b[36m0.6944\u001b[0m       \u001b[32m0.5896\u001b[0m        \u001b[35m0.6893\u001b[0m  0.0213\n",
      "      5        \u001b[36m0.6933\u001b[0m       \u001b[32m0.6045\u001b[0m        \u001b[35m0.6857\u001b[0m  0.0274\n",
      "      6        \u001b[36m0.6748\u001b[0m       \u001b[32m0.6269\u001b[0m        \u001b[35m0.6822\u001b[0m  0.0272\n",
      "      7        0.6795       \u001b[32m0.6418\u001b[0m        \u001b[35m0.6787\u001b[0m  0.0264\n",
      "      8        \u001b[36m0.6681\u001b[0m       \u001b[32m0.6493\u001b[0m        \u001b[35m0.6753\u001b[0m  0.0198\n",
      "      9        0.6759       0.6493        \u001b[35m0.6721\u001b[0m  0.0231\n",
      "     10        0.6725       0.6343        \u001b[35m0.6690\u001b[0m  0.0229\n",
      "     11        0.6694       0.6418        \u001b[35m0.6654\u001b[0m  0.0215\n",
      "     12        \u001b[36m0.6551\u001b[0m       0.6343        \u001b[35m0.6617\u001b[0m  0.0189\n",
      "     13        \u001b[36m0.6496\u001b[0m       0.6418        \u001b[35m0.6577\u001b[0m  0.0203\n",
      "     14        \u001b[36m0.6435\u001b[0m       0.6418        \u001b[35m0.6537\u001b[0m  0.0212\n",
      "     15        0.6544       0.6269        \u001b[35m0.6499\u001b[0m  0.0252\n",
      "     16        0.6457       0.6493        \u001b[35m0.6459\u001b[0m  0.0230\n",
      "     17        \u001b[36m0.6319\u001b[0m       \u001b[32m0.6567\u001b[0m        \u001b[35m0.6416\u001b[0m  0.0245\n",
      "     18        0.6378       0.6567        \u001b[35m0.6371\u001b[0m  0.0227\n",
      "     19        0.6327       \u001b[32m0.6642\u001b[0m        \u001b[35m0.6326\u001b[0m  0.0216\n",
      "     20        \u001b[36m0.6131\u001b[0m       0.6642        \u001b[35m0.6281\u001b[0m  0.0266\n",
      "[CV] END .lr=0.05, module__dropout=0.5, module__num_units=10; total time=   0.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7139\u001b[0m       \u001b[32m0.5224\u001b[0m        \u001b[35m0.6986\u001b[0m  0.0247\n",
      "      2        \u001b[36m0.6987\u001b[0m       \u001b[32m0.5373\u001b[0m        \u001b[35m0.6956\u001b[0m  0.0241\n",
      "      3        \u001b[36m0.6948\u001b[0m       \u001b[32m0.5448\u001b[0m        \u001b[35m0.6931\u001b[0m  0.0214\n",
      "      4        \u001b[36m0.6897\u001b[0m       0.5373        \u001b[35m0.6908\u001b[0m  0.0218\n",
      "      5        \u001b[36m0.6896\u001b[0m       \u001b[32m0.5597\u001b[0m        \u001b[35m0.6886\u001b[0m  0.0255\n",
      "      6        \u001b[36m0.6833\u001b[0m       \u001b[32m0.5672\u001b[0m        \u001b[35m0.6862\u001b[0m  0.0226\n",
      "      7        \u001b[36m0.6751\u001b[0m       0.5672        \u001b[35m0.6834\u001b[0m  0.0219\n",
      "      8        0.6816       \u001b[32m0.5896\u001b[0m        \u001b[35m0.6803\u001b[0m  0.0229\n",
      "      9        0.6803       \u001b[32m0.5970\u001b[0m        \u001b[35m0.6768\u001b[0m  0.0251\n",
      "     10        \u001b[36m0.6651\u001b[0m       \u001b[32m0.6045\u001b[0m        \u001b[35m0.6732\u001b[0m  0.0229\n",
      "     11        \u001b[36m0.6578\u001b[0m       0.6045        \u001b[35m0.6696\u001b[0m  0.0217\n",
      "     12        0.6701       \u001b[32m0.6269\u001b[0m        \u001b[35m0.6661\u001b[0m  0.0217\n",
      "     13        0.6633       0.6269        \u001b[35m0.6628\u001b[0m  0.0208\n",
      "     14        \u001b[36m0.6549\u001b[0m       \u001b[32m0.6418\u001b[0m        \u001b[35m0.6598\u001b[0m  0.0255\n",
      "     15        \u001b[36m0.6440\u001b[0m       \u001b[32m0.6493\u001b[0m        \u001b[35m0.6570\u001b[0m  0.0245\n",
      "     16        \u001b[36m0.6355\u001b[0m       \u001b[32m0.6716\u001b[0m        \u001b[35m0.6536\u001b[0m  0.0210\n",
      "     17        0.6385       \u001b[32m0.6791\u001b[0m        \u001b[35m0.6503\u001b[0m  0.0210\n",
      "     18        0.6364       \u001b[32m0.6866\u001b[0m        \u001b[35m0.6470\u001b[0m  0.0214\n",
      "     19        \u001b[36m0.6273\u001b[0m       0.6866        \u001b[35m0.6437\u001b[0m  0.0249\n",
      "     20        0.6286       \u001b[32m0.6940\u001b[0m        \u001b[35m0.6408\u001b[0m  0.0659\n",
      "[CV] END .lr=0.05, module__dropout=0.5, module__num_units=10; total time=   0.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7253\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7155\u001b[0m  0.0342\n",
      "      2        \u001b[36m0.7159\u001b[0m       0.5000        \u001b[35m0.7101\u001b[0m  0.0322\n",
      "      3        \u001b[36m0.7123\u001b[0m       0.5000        \u001b[35m0.7046\u001b[0m  0.0245\n",
      "      4        \u001b[36m0.7118\u001b[0m       0.5000        \u001b[35m0.6996\u001b[0m  0.0247\n",
      "      5        \u001b[36m0.6999\u001b[0m       \u001b[32m0.5075\u001b[0m        \u001b[35m0.6948\u001b[0m  0.0236\n",
      "      6        \u001b[36m0.6916\u001b[0m       0.5075        \u001b[35m0.6904\u001b[0m  0.0251\n",
      "      7        \u001b[36m0.6910\u001b[0m       0.4925        \u001b[35m0.6861\u001b[0m  0.0262\n",
      "      8        \u001b[36m0.6871\u001b[0m       \u001b[32m0.5149\u001b[0m        \u001b[35m0.6819\u001b[0m  0.0246\n",
      "      9        \u001b[36m0.6813\u001b[0m       \u001b[32m0.5299\u001b[0m        \u001b[35m0.6778\u001b[0m  0.0271\n",
      "     10        0.6821       \u001b[32m0.5522\u001b[0m        \u001b[35m0.6737\u001b[0m  0.0236\n",
      "     11        \u001b[36m0.6694\u001b[0m       \u001b[32m0.5896\u001b[0m        \u001b[35m0.6690\u001b[0m  0.0247\n",
      "     12        0.6721       \u001b[32m0.6343\u001b[0m        \u001b[35m0.6635\u001b[0m  0.0230\n",
      "     13        \u001b[36m0.6679\u001b[0m       \u001b[32m0.6716\u001b[0m        \u001b[35m0.6578\u001b[0m  0.0212\n",
      "     14        \u001b[36m0.6668\u001b[0m       \u001b[32m0.6866\u001b[0m        \u001b[35m0.6520\u001b[0m  0.0257\n",
      "     15        \u001b[36m0.6537\u001b[0m       \u001b[32m0.7090\u001b[0m        \u001b[35m0.6458\u001b[0m  0.0233\n",
      "     16        \u001b[36m0.6490\u001b[0m       \u001b[32m0.7239\u001b[0m        \u001b[35m0.6387\u001b[0m  0.0232\n",
      "     17        \u001b[36m0.6386\u001b[0m       0.7164        \u001b[35m0.6312\u001b[0m  0.0242\n",
      "     18        \u001b[36m0.6349\u001b[0m       \u001b[32m0.7388\u001b[0m        \u001b[35m0.6234\u001b[0m  0.0223\n",
      "     19        \u001b[36m0.6290\u001b[0m       \u001b[32m0.7463\u001b[0m        \u001b[35m0.6153\u001b[0m  0.0217\n",
      "     20        \u001b[36m0.6216\u001b[0m       0.7313        \u001b[35m0.6074\u001b[0m  0.0248\n",
      "[CV] END .lr=0.05, module__dropout=0.5, module__num_units=20; total time=   0.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7160\u001b[0m       \u001b[32m0.4627\u001b[0m        \u001b[35m0.7012\u001b[0m  0.0216\n",
      "      2        \u001b[36m0.6996\u001b[0m       \u001b[32m0.5224\u001b[0m        \u001b[35m0.6943\u001b[0m  0.0232\n",
      "      3        \u001b[36m0.6968\u001b[0m       \u001b[32m0.5746\u001b[0m        \u001b[35m0.6881\u001b[0m  0.0246\n",
      "      4        \u001b[36m0.6900\u001b[0m       \u001b[32m0.5896\u001b[0m        \u001b[35m0.6822\u001b[0m  0.0220\n",
      "      5        \u001b[36m0.6700\u001b[0m       \u001b[32m0.5970\u001b[0m        \u001b[35m0.6770\u001b[0m  0.0198\n",
      "      6        0.6793       \u001b[32m0.6045\u001b[0m        \u001b[35m0.6718\u001b[0m  0.0279\n",
      "      7        \u001b[36m0.6636\u001b[0m       \u001b[32m0.6493\u001b[0m        \u001b[35m0.6661\u001b[0m  0.0216\n",
      "      8        \u001b[36m0.6598\u001b[0m       0.6493        \u001b[35m0.6602\u001b[0m  0.0220\n",
      "      9        \u001b[36m0.6488\u001b[0m       0.6418        \u001b[35m0.6542\u001b[0m  0.0223\n",
      "     10        0.6490       \u001b[32m0.6791\u001b[0m        \u001b[35m0.6483\u001b[0m  0.0255\n",
      "     11        \u001b[36m0.6367\u001b[0m       0.6791        \u001b[35m0.6423\u001b[0m  0.0257\n",
      "     12        \u001b[36m0.6260\u001b[0m       \u001b[32m0.6866\u001b[0m        \u001b[35m0.6362\u001b[0m  0.0209\n",
      "     13        \u001b[36m0.6117\u001b[0m       0.6791        \u001b[35m0.6295\u001b[0m  0.0241\n",
      "     14        0.6147       \u001b[32m0.6940\u001b[0m        \u001b[35m0.6227\u001b[0m  0.0238\n",
      "     15        0.6178       \u001b[32m0.7015\u001b[0m        \u001b[35m0.6168\u001b[0m  0.0227\n",
      "     16        \u001b[36m0.6114\u001b[0m       \u001b[32m0.7090\u001b[0m        \u001b[35m0.6112\u001b[0m  0.0247\n",
      "     17        \u001b[36m0.5973\u001b[0m       0.7090        \u001b[35m0.6057\u001b[0m  0.0215\n",
      "     18        0.6032       \u001b[32m0.7164\u001b[0m        \u001b[35m0.6003\u001b[0m  0.0222\n",
      "     19        \u001b[36m0.5840\u001b[0m       0.7015        \u001b[35m0.5957\u001b[0m  0.0216\n",
      "     20        0.5913       0.7015        \u001b[35m0.5913\u001b[0m  0.0220\n",
      "[CV] END .lr=0.05, module__dropout=0.5, module__num_units=20; total time=   0.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7307\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7095\u001b[0m  0.0263\n",
      "      2        \u001b[36m0.7175\u001b[0m       0.5000        \u001b[35m0.7034\u001b[0m  0.0230\n",
      "      3        \u001b[36m0.7105\u001b[0m       \u001b[32m0.5075\u001b[0m        \u001b[35m0.6984\u001b[0m  0.0229\n",
      "      4        \u001b[36m0.7033\u001b[0m       0.5075        \u001b[35m0.6937\u001b[0m  0.0212\n",
      "      5        \u001b[36m0.6961\u001b[0m       \u001b[32m0.5224\u001b[0m        \u001b[35m0.6898\u001b[0m  0.0214\n",
      "      6        0.7011       \u001b[32m0.5299\u001b[0m        \u001b[35m0.6865\u001b[0m  0.0211\n",
      "      7        \u001b[36m0.6900\u001b[0m       \u001b[32m0.5373\u001b[0m        \u001b[35m0.6836\u001b[0m  0.0249\n",
      "      8        \u001b[36m0.6892\u001b[0m       \u001b[32m0.5522\u001b[0m        \u001b[35m0.6809\u001b[0m  0.0210\n",
      "      9        \u001b[36m0.6822\u001b[0m       \u001b[32m0.5746\u001b[0m        \u001b[35m0.6779\u001b[0m  0.0226\n",
      "     10        \u001b[36m0.6772\u001b[0m       \u001b[32m0.5970\u001b[0m        \u001b[35m0.6750\u001b[0m  0.0220\n",
      "     11        \u001b[36m0.6749\u001b[0m       0.5896        \u001b[35m0.6721\u001b[0m  0.0214\n",
      "     12        \u001b[36m0.6707\u001b[0m       0.5970        \u001b[35m0.6692\u001b[0m  0.0264\n",
      "     13        \u001b[36m0.6704\u001b[0m       \u001b[32m0.6045\u001b[0m        \u001b[35m0.6664\u001b[0m  0.0235\n",
      "     14        \u001b[36m0.6628\u001b[0m       \u001b[32m0.6119\u001b[0m        \u001b[35m0.6634\u001b[0m  0.0235\n",
      "     15        \u001b[36m0.6615\u001b[0m       0.6119        \u001b[35m0.6604\u001b[0m  0.0219\n",
      "     16        \u001b[36m0.6506\u001b[0m       \u001b[32m0.6194\u001b[0m        \u001b[35m0.6572\u001b[0m  0.0858\n",
      "     17        \u001b[36m0.6484\u001b[0m       \u001b[32m0.6269\u001b[0m        \u001b[35m0.6538\u001b[0m  0.0311\n",
      "     18        \u001b[36m0.6413\u001b[0m       0.6194        \u001b[35m0.6503\u001b[0m  0.0268\n",
      "     19        \u001b[36m0.6359\u001b[0m       \u001b[32m0.6493\u001b[0m        \u001b[35m0.6467\u001b[0m  0.0222\n",
      "     20        \u001b[36m0.6249\u001b[0m       \u001b[32m0.6567\u001b[0m        \u001b[35m0.6427\u001b[0m  0.0248\n",
      "[CV] END .lr=0.05, module__dropout=0.5, module__num_units=20; total time=   0.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7066\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7069\u001b[0m  0.0221\n",
      "      2        \u001b[36m0.6997\u001b[0m       0.5000        \u001b[35m0.7013\u001b[0m  0.0221\n",
      "      3        \u001b[36m0.6944\u001b[0m       0.5000        \u001b[35m0.6968\u001b[0m  0.0217\n",
      "      4        \u001b[36m0.6899\u001b[0m       0.5000        \u001b[35m0.6930\u001b[0m  0.0276\n",
      "      5        \u001b[36m0.6860\u001b[0m       0.5000        \u001b[35m0.6896\u001b[0m  0.0220\n",
      "      6        \u001b[36m0.6823\u001b[0m       \u001b[32m0.5075\u001b[0m        \u001b[35m0.6864\u001b[0m  0.0221\n",
      "      7        \u001b[36m0.6788\u001b[0m       \u001b[32m0.5149\u001b[0m        \u001b[35m0.6833\u001b[0m  0.0226\n",
      "      8        \u001b[36m0.6752\u001b[0m       \u001b[32m0.5373\u001b[0m        \u001b[35m0.6801\u001b[0m  0.0238\n",
      "      9        \u001b[36m0.6713\u001b[0m       \u001b[32m0.5970\u001b[0m        \u001b[35m0.6769\u001b[0m  0.0266\n",
      "     10        \u001b[36m0.6673\u001b[0m       0.5896        \u001b[35m0.6733\u001b[0m  0.0230\n",
      "     11        \u001b[36m0.6629\u001b[0m       0.5970        \u001b[35m0.6695\u001b[0m  0.0222\n",
      "     12        \u001b[36m0.6582\u001b[0m       0.5896        \u001b[35m0.6657\u001b[0m  0.0268\n",
      "     13        \u001b[36m0.6533\u001b[0m       0.5672        \u001b[35m0.6618\u001b[0m  0.0210\n",
      "     14        \u001b[36m0.6480\u001b[0m       0.5746        \u001b[35m0.6577\u001b[0m  0.0213\n",
      "     15        \u001b[36m0.6423\u001b[0m       0.5821        \u001b[35m0.6534\u001b[0m  0.0239\n",
      "     16        \u001b[36m0.6364\u001b[0m       \u001b[32m0.6194\u001b[0m        \u001b[35m0.6488\u001b[0m  0.0267\n",
      "     17        \u001b[36m0.6301\u001b[0m       \u001b[32m0.6343\u001b[0m        \u001b[35m0.6439\u001b[0m  0.0247\n",
      "     18        \u001b[36m0.6234\u001b[0m       \u001b[32m0.6418\u001b[0m        \u001b[35m0.6387\u001b[0m  0.0201\n",
      "     19        \u001b[36m0.6163\u001b[0m       \u001b[32m0.6642\u001b[0m        \u001b[35m0.6333\u001b[0m  0.0232\n",
      "     20        \u001b[36m0.6089\u001b[0m       0.6567        \u001b[35m0.6276\u001b[0m  0.0248\n",
      "[CV] END ....lr=0.1, module__dropout=0, module__num_units=10; total time=   0.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7003\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.6957\u001b[0m  0.0213\n",
      "      2        \u001b[36m0.6932\u001b[0m       \u001b[32m0.5299\u001b[0m        \u001b[35m0.6908\u001b[0m  0.0247\n",
      "      3        \u001b[36m0.6870\u001b[0m       0.5299        \u001b[35m0.6862\u001b[0m  0.0220\n",
      "      4        \u001b[36m0.6808\u001b[0m       \u001b[32m0.5597\u001b[0m        \u001b[35m0.6815\u001b[0m  0.0232\n",
      "      5        \u001b[36m0.6747\u001b[0m       \u001b[32m0.5746\u001b[0m        \u001b[35m0.6770\u001b[0m  0.0231\n",
      "      6        \u001b[36m0.6686\u001b[0m       \u001b[32m0.5970\u001b[0m        \u001b[35m0.6729\u001b[0m  0.0255\n",
      "      7        \u001b[36m0.6627\u001b[0m       \u001b[32m0.6418\u001b[0m        \u001b[35m0.6684\u001b[0m  0.0250\n",
      "      8        \u001b[36m0.6569\u001b[0m       0.6269        \u001b[35m0.6641\u001b[0m  0.0213\n",
      "      9        \u001b[36m0.6511\u001b[0m       0.6269        \u001b[35m0.6598\u001b[0m  0.0194\n",
      "     10        \u001b[36m0.6453\u001b[0m       \u001b[32m0.6493\u001b[0m        \u001b[35m0.6559\u001b[0m  0.0241\n",
      "     11        \u001b[36m0.6394\u001b[0m       0.6418        \u001b[35m0.6520\u001b[0m  0.0237\n",
      "     12        \u001b[36m0.6332\u001b[0m       0.6418        \u001b[35m0.6479\u001b[0m  0.0230\n",
      "     13        \u001b[36m0.6267\u001b[0m       0.6343        \u001b[35m0.6437\u001b[0m  0.0236\n",
      "     14        \u001b[36m0.6197\u001b[0m       0.6343        \u001b[35m0.6391\u001b[0m  0.0210\n",
      "     15        \u001b[36m0.6123\u001b[0m       0.6343        \u001b[35m0.6342\u001b[0m  0.0192\n",
      "     16        \u001b[36m0.6045\u001b[0m       0.6269        \u001b[35m0.6289\u001b[0m  0.0221\n",
      "     17        \u001b[36m0.5961\u001b[0m       0.6493        \u001b[35m0.6233\u001b[0m  0.0236\n",
      "     18        \u001b[36m0.5870\u001b[0m       0.6493        \u001b[35m0.6174\u001b[0m  0.0244\n",
      "     19        \u001b[36m0.5775\u001b[0m       \u001b[32m0.6567\u001b[0m        \u001b[35m0.6111\u001b[0m  0.0248\n",
      "     20        \u001b[36m0.5676\u001b[0m       \u001b[32m0.6642\u001b[0m        \u001b[35m0.6049\u001b[0m  0.0259\n",
      "[CV] END ....lr=0.1, module__dropout=0, module__num_units=10; total time=   0.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7129\u001b[0m       \u001b[32m0.5075\u001b[0m        \u001b[35m0.7074\u001b[0m  0.0226\n",
      "      2        \u001b[36m0.7048\u001b[0m       \u001b[32m0.5149\u001b[0m        \u001b[35m0.7026\u001b[0m  0.0251\n",
      "      3        \u001b[36m0.6975\u001b[0m       0.5149        \u001b[35m0.6978\u001b[0m  0.0270\n",
      "      4        \u001b[36m0.6902\u001b[0m       0.5075        \u001b[35m0.6932\u001b[0m  0.0274\n",
      "      5        \u001b[36m0.6830\u001b[0m       \u001b[32m0.5224\u001b[0m        \u001b[35m0.6888\u001b[0m  0.0298\n",
      "      6        \u001b[36m0.6757\u001b[0m       \u001b[32m0.5522\u001b[0m        \u001b[35m0.6848\u001b[0m  0.0298\n",
      "      7        \u001b[36m0.6680\u001b[0m       \u001b[32m0.5821\u001b[0m        \u001b[35m0.6811\u001b[0m  0.0242\n",
      "      8        \u001b[36m0.6604\u001b[0m       \u001b[32m0.5896\u001b[0m        \u001b[35m0.6777\u001b[0m  0.0278\n",
      "      9        \u001b[36m0.6527\u001b[0m       \u001b[32m0.6269\u001b[0m        \u001b[35m0.6746\u001b[0m  0.0902\n",
      "     10        \u001b[36m0.6449\u001b[0m       \u001b[32m0.6493\u001b[0m        \u001b[35m0.6716\u001b[0m  0.0394\n",
      "     11        \u001b[36m0.6371\u001b[0m       0.6343        \u001b[35m0.6691\u001b[0m  0.0343\n",
      "     12        \u001b[36m0.6294\u001b[0m       0.6343        \u001b[35m0.6671\u001b[0m  0.0315\n",
      "     13        \u001b[36m0.6218\u001b[0m       0.6343        \u001b[35m0.6656\u001b[0m  0.0298\n",
      "     14        \u001b[36m0.6144\u001b[0m       0.6418        \u001b[35m0.6646\u001b[0m  0.0218\n",
      "     15        \u001b[36m0.6074\u001b[0m       0.6418        \u001b[35m0.6639\u001b[0m  0.0208\n",
      "     16        \u001b[36m0.6008\u001b[0m       0.6418        \u001b[35m0.6634\u001b[0m  0.0260\n",
      "     17        \u001b[36m0.5947\u001b[0m       \u001b[32m0.6567\u001b[0m        \u001b[35m0.6633\u001b[0m  0.0224\n",
      "     18        \u001b[36m0.5889\u001b[0m       \u001b[32m0.6716\u001b[0m        0.6634  0.0194\n",
      "     19        \u001b[36m0.5833\u001b[0m       \u001b[32m0.6866\u001b[0m        0.6636  0.0822\n",
      "     20        \u001b[36m0.5780\u001b[0m       0.6866        0.6638  0.0263\n",
      "[CV] END ....lr=0.1, module__dropout=0, module__num_units=10; total time=   0.7s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6802\u001b[0m       \u001b[32m0.5746\u001b[0m        \u001b[35m0.6751\u001b[0m  0.0207\n",
      "      2        \u001b[36m0.6693\u001b[0m       0.5597        \u001b[35m0.6662\u001b[0m  0.0284\n",
      "      3        \u001b[36m0.6597\u001b[0m       \u001b[32m0.5896\u001b[0m        \u001b[35m0.6573\u001b[0m  0.0283\n",
      "      4        \u001b[36m0.6503\u001b[0m       \u001b[32m0.6119\u001b[0m        \u001b[35m0.6481\u001b[0m  0.0260\n",
      "      5        \u001b[36m0.6409\u001b[0m       0.6119        \u001b[35m0.6388\u001b[0m  0.0260\n",
      "      6        \u001b[36m0.6316\u001b[0m       \u001b[32m0.6343\u001b[0m        \u001b[35m0.6298\u001b[0m  0.0263\n",
      "      7        \u001b[36m0.6221\u001b[0m       \u001b[32m0.6567\u001b[0m        \u001b[35m0.6209\u001b[0m  0.0237\n",
      "      8        \u001b[36m0.6123\u001b[0m       \u001b[32m0.6642\u001b[0m        \u001b[35m0.6122\u001b[0m  0.0225\n",
      "      9        \u001b[36m0.6022\u001b[0m       \u001b[32m0.6791\u001b[0m        \u001b[35m0.6033\u001b[0m  0.0214\n",
      "     10        \u001b[36m0.5920\u001b[0m       \u001b[32m0.6866\u001b[0m        \u001b[35m0.5944\u001b[0m  0.0210\n",
      "     11        \u001b[36m0.5815\u001b[0m       \u001b[32m0.6940\u001b[0m        \u001b[35m0.5851\u001b[0m  0.0214\n",
      "     12        \u001b[36m0.5707\u001b[0m       0.6940        \u001b[35m0.5757\u001b[0m  0.0235\n",
      "     13        \u001b[36m0.5596\u001b[0m       \u001b[32m0.7090\u001b[0m        \u001b[35m0.5665\u001b[0m  0.0249\n",
      "     14        \u001b[36m0.5482\u001b[0m       \u001b[32m0.7164\u001b[0m        \u001b[35m0.5572\u001b[0m  0.0247\n",
      "     15        \u001b[36m0.5367\u001b[0m       \u001b[32m0.7537\u001b[0m        \u001b[35m0.5478\u001b[0m  0.0214\n",
      "     16        \u001b[36m0.5251\u001b[0m       \u001b[32m0.7612\u001b[0m        \u001b[35m0.5385\u001b[0m  0.0243\n",
      "     17        \u001b[36m0.5132\u001b[0m       0.7612        \u001b[35m0.5295\u001b[0m  0.0238\n",
      "     18        \u001b[36m0.5014\u001b[0m       0.7537        \u001b[35m0.5210\u001b[0m  0.0263\n",
      "     19        \u001b[36m0.4896\u001b[0m       0.7612        \u001b[35m0.5132\u001b[0m  0.0287\n",
      "     20        \u001b[36m0.4780\u001b[0m       0.7612        \u001b[35m0.5059\u001b[0m  0.0227\n",
      "[CV] END ....lr=0.1, module__dropout=0, module__num_units=20; total time=   0.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7006\u001b[0m       \u001b[32m0.4851\u001b[0m        \u001b[35m0.6989\u001b[0m  0.0283\n",
      "      2        \u001b[36m0.6932\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.6938\u001b[0m  0.0271\n",
      "      3        \u001b[36m0.6867\u001b[0m       \u001b[32m0.5448\u001b[0m        \u001b[35m0.6886\u001b[0m  0.0247\n",
      "      4        \u001b[36m0.6803\u001b[0m       \u001b[32m0.5597\u001b[0m        \u001b[35m0.6831\u001b[0m  0.0229\n",
      "      5        \u001b[36m0.6739\u001b[0m       \u001b[32m0.5672\u001b[0m        \u001b[35m0.6772\u001b[0m  0.0216\n",
      "      6        \u001b[36m0.6671\u001b[0m       \u001b[32m0.5896\u001b[0m        \u001b[35m0.6710\u001b[0m  0.0232\n",
      "      7        \u001b[36m0.6601\u001b[0m       \u001b[32m0.6269\u001b[0m        \u001b[35m0.6648\u001b[0m  0.0237\n",
      "      8        \u001b[36m0.6528\u001b[0m       0.6269        \u001b[35m0.6588\u001b[0m  0.0251\n",
      "      9        \u001b[36m0.6453\u001b[0m       \u001b[32m0.6493\u001b[0m        \u001b[35m0.6530\u001b[0m  0.0214\n",
      "     10        \u001b[36m0.6376\u001b[0m       0.6343        \u001b[35m0.6472\u001b[0m  0.0249\n",
      "     11        \u001b[36m0.6295\u001b[0m       0.6418        \u001b[35m0.6414\u001b[0m  0.0262\n",
      "     12        \u001b[36m0.6212\u001b[0m       0.6418        \u001b[35m0.6355\u001b[0m  0.0260\n",
      "     13        \u001b[36m0.6126\u001b[0m       0.6493        \u001b[35m0.6294\u001b[0m  0.0272\n",
      "     14        \u001b[36m0.6036\u001b[0m       \u001b[32m0.6567\u001b[0m        \u001b[35m0.6231\u001b[0m  0.0256\n",
      "     15        \u001b[36m0.5943\u001b[0m       \u001b[32m0.6642\u001b[0m        \u001b[35m0.6167\u001b[0m  0.0199\n",
      "     16        \u001b[36m0.5846\u001b[0m       0.6567        \u001b[35m0.6101\u001b[0m  0.0246\n",
      "     17        \u001b[36m0.5746\u001b[0m       0.6642        \u001b[35m0.6035\u001b[0m  0.0213\n",
      "     18        \u001b[36m0.5642\u001b[0m       \u001b[32m0.6791\u001b[0m        \u001b[35m0.5965\u001b[0m  0.0249\n",
      "     19        \u001b[36m0.5536\u001b[0m       0.6791        \u001b[35m0.5894\u001b[0m  0.0276\n",
      "     20        \u001b[36m0.5428\u001b[0m       0.6791        \u001b[35m0.5827\u001b[0m  0.0233\n",
      "[CV] END ....lr=0.1, module__dropout=0, module__num_units=20; total time=   0.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6913\u001b[0m       \u001b[32m0.5448\u001b[0m        \u001b[35m0.6890\u001b[0m  0.0207\n",
      "      2        \u001b[36m0.6797\u001b[0m       \u001b[32m0.5597\u001b[0m        \u001b[35m0.6838\u001b[0m  0.0201\n",
      "      3        \u001b[36m0.6703\u001b[0m       \u001b[32m0.5970\u001b[0m        \u001b[35m0.6785\u001b[0m  0.0212\n",
      "      4        \u001b[36m0.6609\u001b[0m       0.5672        \u001b[35m0.6735\u001b[0m  0.0243\n",
      "      5        \u001b[36m0.6517\u001b[0m       0.5821        \u001b[35m0.6690\u001b[0m  0.0216\n",
      "      6        \u001b[36m0.6430\u001b[0m       0.5896        \u001b[35m0.6650\u001b[0m  0.0265\n",
      "      7        \u001b[36m0.6349\u001b[0m       0.5821        \u001b[35m0.6621\u001b[0m  0.0219\n",
      "      8        \u001b[36m0.6271\u001b[0m       0.5896        \u001b[35m0.6595\u001b[0m  0.0223\n",
      "      9        \u001b[36m0.6195\u001b[0m       0.5896        \u001b[35m0.6575\u001b[0m  0.0224\n",
      "     10        \u001b[36m0.6124\u001b[0m       0.5970        \u001b[35m0.6560\u001b[0m  0.0233\n",
      "     11        \u001b[36m0.6053\u001b[0m       \u001b[32m0.6194\u001b[0m        \u001b[35m0.6550\u001b[0m  0.0204\n",
      "     12        \u001b[36m0.5982\u001b[0m       \u001b[32m0.6269\u001b[0m        \u001b[35m0.6539\u001b[0m  0.0242\n",
      "     13        \u001b[36m0.5909\u001b[0m       \u001b[32m0.6418\u001b[0m        \u001b[35m0.6525\u001b[0m  0.0242\n",
      "     14        \u001b[36m0.5834\u001b[0m       \u001b[32m0.6493\u001b[0m        \u001b[35m0.6504\u001b[0m  0.0230\n",
      "     15        \u001b[36m0.5758\u001b[0m       0.6493        \u001b[35m0.6473\u001b[0m  0.0267\n",
      "     16        \u001b[36m0.5678\u001b[0m       \u001b[32m0.6567\u001b[0m        \u001b[35m0.6435\u001b[0m  0.0225\n",
      "     17        \u001b[36m0.5595\u001b[0m       0.6567        \u001b[35m0.6390\u001b[0m  0.0270\n",
      "     18        \u001b[36m0.5510\u001b[0m       \u001b[32m0.6642\u001b[0m        \u001b[35m0.6338\u001b[0m  0.0240\n",
      "     19        \u001b[36m0.5421\u001b[0m       0.6642        \u001b[35m0.6282\u001b[0m  0.0220\n",
      "     20        \u001b[36m0.5329\u001b[0m       \u001b[32m0.6791\u001b[0m        \u001b[35m0.6220\u001b[0m  0.0235\n",
      "[CV] END ....lr=0.1, module__dropout=0, module__num_units=20; total time=   0.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6928\u001b[0m       \u001b[32m0.5896\u001b[0m        \u001b[35m0.6750\u001b[0m  0.1186\n",
      "      2        \u001b[36m0.6855\u001b[0m       \u001b[32m0.6045\u001b[0m        \u001b[35m0.6714\u001b[0m  0.0234\n",
      "      3        \u001b[36m0.6839\u001b[0m       \u001b[32m0.6194\u001b[0m        \u001b[35m0.6673\u001b[0m  0.0230\n",
      "      4        \u001b[36m0.6782\u001b[0m       \u001b[32m0.6567\u001b[0m        \u001b[35m0.6632\u001b[0m  0.0286\n",
      "      5        \u001b[36m0.6645\u001b[0m       \u001b[32m0.6866\u001b[0m        \u001b[35m0.6591\u001b[0m  0.0284\n",
      "      6        \u001b[36m0.6589\u001b[0m       \u001b[32m0.6940\u001b[0m        \u001b[35m0.6548\u001b[0m  0.0281\n",
      "      7        \u001b[36m0.6543\u001b[0m       \u001b[32m0.7239\u001b[0m        \u001b[35m0.6500\u001b[0m  0.0259\n",
      "      8        \u001b[36m0.6483\u001b[0m       0.7239        \u001b[35m0.6449\u001b[0m  0.0256\n",
      "      9        0.6538       0.7239        \u001b[35m0.6402\u001b[0m  0.0228\n",
      "     10        0.6509       \u001b[32m0.7313\u001b[0m        \u001b[35m0.6355\u001b[0m  0.0235\n",
      "     11        \u001b[36m0.6470\u001b[0m       \u001b[32m0.7388\u001b[0m        \u001b[35m0.6310\u001b[0m  0.0372\n",
      "     12        \u001b[36m0.6389\u001b[0m       \u001b[32m0.7463\u001b[0m        \u001b[35m0.6263\u001b[0m  0.0443\n",
      "     13        \u001b[36m0.6375\u001b[0m       \u001b[32m0.7537\u001b[0m        \u001b[35m0.6216\u001b[0m  0.0300\n",
      "     14        \u001b[36m0.6332\u001b[0m       0.7463        \u001b[35m0.6170\u001b[0m  0.0271\n",
      "     15        \u001b[36m0.6179\u001b[0m       0.7463        \u001b[35m0.6123\u001b[0m  0.0241\n",
      "     16        \u001b[36m0.6127\u001b[0m       \u001b[32m0.7612\u001b[0m        \u001b[35m0.6072\u001b[0m  0.0295\n",
      "     17        0.6168       \u001b[32m0.7687\u001b[0m        \u001b[35m0.6027\u001b[0m  0.0242\n",
      "     18        0.6187       0.7687        \u001b[35m0.5987\u001b[0m  0.0248\n",
      "     19        \u001b[36m0.6104\u001b[0m       0.7687        \u001b[35m0.5947\u001b[0m  0.0206\n",
      "     20        0.6209       0.7687        \u001b[35m0.5912\u001b[0m  0.0213\n",
      "[CV] END ..lr=0.1, module__dropout=0.5, module__num_units=10; total time=   0.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7186\u001b[0m       \u001b[32m0.5522\u001b[0m        \u001b[35m0.6846\u001b[0m  0.0247\n",
      "      2        \u001b[36m0.7113\u001b[0m       \u001b[32m0.5746\u001b[0m        \u001b[35m0.6796\u001b[0m  0.0252\n",
      "      3        \u001b[36m0.7066\u001b[0m       \u001b[32m0.5821\u001b[0m        \u001b[35m0.6759\u001b[0m  0.0257\n",
      "      4        0.7151       0.5821        \u001b[35m0.6729\u001b[0m  0.0216\n",
      "      5        \u001b[36m0.6989\u001b[0m       0.5746        \u001b[35m0.6702\u001b[0m  0.0217\n",
      "      6        \u001b[36m0.6875\u001b[0m       \u001b[32m0.5970\u001b[0m        \u001b[35m0.6681\u001b[0m  0.0226\n",
      "      7        \u001b[36m0.6867\u001b[0m       \u001b[32m0.6045\u001b[0m        \u001b[35m0.6659\u001b[0m  0.0252\n",
      "      8        \u001b[36m0.6863\u001b[0m       0.5970        \u001b[35m0.6637\u001b[0m  0.0245\n",
      "      9        \u001b[36m0.6830\u001b[0m       \u001b[32m0.6194\u001b[0m        \u001b[35m0.6617\u001b[0m  0.0213\n",
      "     10        \u001b[36m0.6612\u001b[0m       0.6194        \u001b[35m0.6596\u001b[0m  0.0248\n",
      "     11        0.6665       \u001b[32m0.6418\u001b[0m        \u001b[35m0.6575\u001b[0m  0.0214\n",
      "     12        \u001b[36m0.6546\u001b[0m       \u001b[32m0.6493\u001b[0m        \u001b[35m0.6553\u001b[0m  0.0286\n",
      "     13        0.6674       0.6418        \u001b[35m0.6532\u001b[0m  0.0253\n",
      "     14        0.6600       0.6343        \u001b[35m0.6513\u001b[0m  0.0231\n",
      "     15        0.6591       0.6343        \u001b[35m0.6495\u001b[0m  0.0219\n",
      "     16        0.6575       0.6343        \u001b[35m0.6477\u001b[0m  0.0227\n",
      "     17        0.6626       0.6343        \u001b[35m0.6458\u001b[0m  0.0211\n",
      "     18        \u001b[36m0.6496\u001b[0m       \u001b[32m0.6642\u001b[0m        \u001b[35m0.6440\u001b[0m  0.0226\n",
      "     19        0.6505       0.6642        \u001b[35m0.6424\u001b[0m  0.0224\n",
      "     20        \u001b[36m0.6432\u001b[0m       \u001b[32m0.6791\u001b[0m        \u001b[35m0.6408\u001b[0m  0.0231\n",
      "[CV] END ..lr=0.1, module__dropout=0.5, module__num_units=10; total time=   0.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7382\u001b[0m       \u001b[32m0.5075\u001b[0m        \u001b[35m0.7199\u001b[0m  0.0230\n",
      "      2        \u001b[36m0.7331\u001b[0m       0.5000        \u001b[35m0.7117\u001b[0m  0.0226\n",
      "      3        \u001b[36m0.7103\u001b[0m       \u001b[32m0.5224\u001b[0m        \u001b[35m0.7047\u001b[0m  0.0212\n",
      "      4        \u001b[36m0.7027\u001b[0m       0.5149        \u001b[35m0.6989\u001b[0m  0.0244\n",
      "      5        \u001b[36m0.6907\u001b[0m       0.5224        \u001b[35m0.6937\u001b[0m  0.0249\n",
      "      6        \u001b[36m0.6889\u001b[0m       \u001b[32m0.5299\u001b[0m        \u001b[35m0.6894\u001b[0m  0.0879\n",
      "      7        \u001b[36m0.6805\u001b[0m       \u001b[32m0.5522\u001b[0m        \u001b[35m0.6861\u001b[0m  0.0268\n",
      "      8        \u001b[36m0.6804\u001b[0m       \u001b[32m0.5896\u001b[0m        \u001b[35m0.6831\u001b[0m  0.0231\n",
      "      9        \u001b[36m0.6717\u001b[0m       \u001b[32m0.6119\u001b[0m        \u001b[35m0.6799\u001b[0m  0.0246\n",
      "     10        \u001b[36m0.6686\u001b[0m       0.6119        \u001b[35m0.6772\u001b[0m  0.0215\n",
      "     11        \u001b[36m0.6618\u001b[0m       \u001b[32m0.6343\u001b[0m        \u001b[35m0.6749\u001b[0m  0.0256\n",
      "     12        \u001b[36m0.6601\u001b[0m       0.6194        \u001b[35m0.6731\u001b[0m  0.0241\n",
      "     13        0.6621       \u001b[32m0.6567\u001b[0m        \u001b[35m0.6714\u001b[0m  0.0245\n",
      "     14        \u001b[36m0.6592\u001b[0m       0.6343        \u001b[35m0.6696\u001b[0m  0.0214\n",
      "     15        0.6635       0.6343        \u001b[35m0.6680\u001b[0m  0.0248\n",
      "     16        \u001b[36m0.6513\u001b[0m       0.6343        \u001b[35m0.6665\u001b[0m  0.0230\n",
      "     17        \u001b[36m0.6474\u001b[0m       0.6418        \u001b[35m0.6648\u001b[0m  0.0273\n",
      "     18        \u001b[36m0.6429\u001b[0m       0.6418        \u001b[35m0.6630\u001b[0m  0.0213\n",
      "     19        0.6547       0.6418        \u001b[35m0.6612\u001b[0m  0.0247\n",
      "     20        \u001b[36m0.6279\u001b[0m       0.6493        \u001b[35m0.6599\u001b[0m  0.0220\n",
      "[CV] END ..lr=0.1, module__dropout=0.5, module__num_units=10; total time=   0.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7095\u001b[0m       \u001b[32m0.5821\u001b[0m        \u001b[35m0.6870\u001b[0m  0.0241\n",
      "      2        \u001b[36m0.6942\u001b[0m       \u001b[32m0.5970\u001b[0m        \u001b[35m0.6796\u001b[0m  0.0250\n",
      "      3        \u001b[36m0.6838\u001b[0m       \u001b[32m0.6567\u001b[0m        \u001b[35m0.6728\u001b[0m  0.0256\n",
      "      4        \u001b[36m0.6744\u001b[0m       \u001b[32m0.6791\u001b[0m        \u001b[35m0.6664\u001b[0m  0.0246\n",
      "      5        \u001b[36m0.6681\u001b[0m       0.6791        \u001b[35m0.6603\u001b[0m  0.0251\n",
      "      6        \u001b[36m0.6630\u001b[0m       \u001b[32m0.6940\u001b[0m        \u001b[35m0.6544\u001b[0m  0.0245\n",
      "      7        0.6642       \u001b[32m0.7090\u001b[0m        \u001b[35m0.6485\u001b[0m  0.0250\n",
      "      8        \u001b[36m0.6513\u001b[0m       \u001b[32m0.7164\u001b[0m        \u001b[35m0.6420\u001b[0m  0.0228\n",
      "      9        \u001b[36m0.6393\u001b[0m       \u001b[32m0.7313\u001b[0m        \u001b[35m0.6349\u001b[0m  0.0237\n",
      "     10        \u001b[36m0.6292\u001b[0m       \u001b[32m0.7537\u001b[0m        \u001b[35m0.6272\u001b[0m  0.0225\n",
      "     11        0.6317       0.7537        \u001b[35m0.6195\u001b[0m  0.0209\n",
      "     12        \u001b[36m0.6267\u001b[0m       0.7537        \u001b[35m0.6116\u001b[0m  0.0234\n",
      "     13        \u001b[36m0.6146\u001b[0m       \u001b[32m0.7612\u001b[0m        \u001b[35m0.6037\u001b[0m  0.0262\n",
      "     14        \u001b[36m0.5980\u001b[0m       0.7612        \u001b[35m0.5953\u001b[0m  0.0239\n",
      "     15        0.6085       \u001b[32m0.7761\u001b[0m        \u001b[35m0.5873\u001b[0m  0.0212\n",
      "     16        \u001b[36m0.5804\u001b[0m       0.7687        \u001b[35m0.5789\u001b[0m  0.0241\n",
      "     17        0.5938       0.7687        \u001b[35m0.5704\u001b[0m  0.0260\n",
      "     18        \u001b[36m0.5782\u001b[0m       0.7612        \u001b[35m0.5620\u001b[0m  0.0244\n",
      "     19        \u001b[36m0.5773\u001b[0m       0.7612        \u001b[35m0.5541\u001b[0m  0.0209\n",
      "     20        \u001b[36m0.5623\u001b[0m       0.7612        \u001b[35m0.5469\u001b[0m  0.0222\n",
      "[CV] END ..lr=0.1, module__dropout=0.5, module__num_units=20; total time=   0.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7312\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7094\u001b[0m  0.0258\n",
      "      2        \u001b[36m0.7088\u001b[0m       0.5000        \u001b[35m0.7027\u001b[0m  0.0242\n",
      "      3        0.7098       0.5000        \u001b[35m0.6971\u001b[0m  0.0272\n",
      "      4        \u001b[36m0.6962\u001b[0m       0.5000        \u001b[35m0.6923\u001b[0m  0.0226\n",
      "      5        \u001b[36m0.6952\u001b[0m       0.5000        \u001b[35m0.6883\u001b[0m  0.0233\n",
      "      6        \u001b[36m0.6866\u001b[0m       0.5000        \u001b[35m0.6847\u001b[0m  0.0221\n",
      "      7        \u001b[36m0.6784\u001b[0m       0.5000        \u001b[35m0.6816\u001b[0m  0.0261\n",
      "      8        \u001b[36m0.6755\u001b[0m       0.5000        \u001b[35m0.6785\u001b[0m  0.0233\n",
      "      9        \u001b[36m0.6683\u001b[0m       0.5000        \u001b[35m0.6755\u001b[0m  0.0254\n",
      "     10        \u001b[36m0.6666\u001b[0m       0.5000        \u001b[35m0.6722\u001b[0m  0.0209\n",
      "     11        0.6759       0.4925        \u001b[35m0.6689\u001b[0m  0.0213\n",
      "     12        \u001b[36m0.6556\u001b[0m       \u001b[32m0.5075\u001b[0m        \u001b[35m0.6653\u001b[0m  0.0209\n",
      "     13        \u001b[36m0.6510\u001b[0m       \u001b[32m0.5373\u001b[0m        \u001b[35m0.6616\u001b[0m  0.0223\n",
      "     14        \u001b[36m0.6452\u001b[0m       0.5299        \u001b[35m0.6577\u001b[0m  0.0224\n",
      "     15        0.6501       \u001b[32m0.5597\u001b[0m        \u001b[35m0.6536\u001b[0m  0.0276\n",
      "     16        \u001b[36m0.6393\u001b[0m       \u001b[32m0.5746\u001b[0m        \u001b[35m0.6495\u001b[0m  0.0240\n",
      "     17        \u001b[36m0.6341\u001b[0m       \u001b[32m0.5896\u001b[0m        \u001b[35m0.6451\u001b[0m  0.0244\n",
      "     18        \u001b[36m0.6149\u001b[0m       0.5821        \u001b[35m0.6406\u001b[0m  0.0198\n",
      "     19        0.6179       \u001b[32m0.5970\u001b[0m        \u001b[35m0.6359\u001b[0m  0.0242\n",
      "     20        \u001b[36m0.6133\u001b[0m       \u001b[32m0.6045\u001b[0m        \u001b[35m0.6310\u001b[0m  0.0224\n",
      "[CV] END ..lr=0.1, module__dropout=0.5, module__num_units=20; total time=   0.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7246\u001b[0m       \u001b[32m0.4851\u001b[0m        \u001b[35m0.7146\u001b[0m  0.0223\n",
      "      2        \u001b[36m0.7118\u001b[0m       0.4627        \u001b[35m0.7056\u001b[0m  0.0215\n",
      "      3        \u001b[36m0.7072\u001b[0m       0.4776        \u001b[35m0.6983\u001b[0m  0.0213\n",
      "      4        \u001b[36m0.6918\u001b[0m       \u001b[32m0.4925\u001b[0m        \u001b[35m0.6923\u001b[0m  0.0262\n",
      "      5        \u001b[36m0.6866\u001b[0m       \u001b[32m0.5149\u001b[0m        \u001b[35m0.6874\u001b[0m  0.0256\n",
      "      6        \u001b[36m0.6755\u001b[0m       \u001b[32m0.5224\u001b[0m        \u001b[35m0.6831\u001b[0m  0.0252\n",
      "      7        \u001b[36m0.6725\u001b[0m       0.5149        \u001b[35m0.6793\u001b[0m  0.0270\n",
      "      8        \u001b[36m0.6664\u001b[0m       \u001b[32m0.5522\u001b[0m        \u001b[35m0.6760\u001b[0m  0.0225\n",
      "      9        \u001b[36m0.6632\u001b[0m       \u001b[32m0.5672\u001b[0m        \u001b[35m0.6727\u001b[0m  0.0218\n",
      "     10        \u001b[36m0.6577\u001b[0m       \u001b[32m0.5821\u001b[0m        \u001b[35m0.6697\u001b[0m  0.0227\n",
      "     11        \u001b[36m0.6535\u001b[0m       0.5746        \u001b[35m0.6666\u001b[0m  0.0210\n",
      "     12        \u001b[36m0.6516\u001b[0m       0.5821        \u001b[35m0.6634\u001b[0m  0.0207\n",
      "     13        \u001b[36m0.6467\u001b[0m       \u001b[32m0.6045\u001b[0m        \u001b[35m0.6602\u001b[0m  0.0274\n",
      "     14        \u001b[36m0.6452\u001b[0m       \u001b[32m0.6194\u001b[0m        \u001b[35m0.6568\u001b[0m  0.0215\n",
      "     15        \u001b[36m0.6351\u001b[0m       \u001b[32m0.6343\u001b[0m        \u001b[35m0.6534\u001b[0m  0.0248\n",
      "     16        \u001b[36m0.6196\u001b[0m       \u001b[32m0.6418\u001b[0m        \u001b[35m0.6499\u001b[0m  0.0242\n",
      "     17        0.6231       \u001b[32m0.6493\u001b[0m        \u001b[35m0.6462\u001b[0m  0.0236\n",
      "     18        0.6276       \u001b[32m0.6567\u001b[0m        \u001b[35m0.6422\u001b[0m  0.0209\n",
      "     19        \u001b[36m0.6105\u001b[0m       0.6567        \u001b[35m0.6380\u001b[0m  0.0255\n",
      "     20        0.6170       0.6493        \u001b[35m0.6339\u001b[0m  0.0716\n",
      "[CV] END ..lr=0.1, module__dropout=0.5, module__num_units=20; total time=   0.5s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=&lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[initialized](\n",
       "  module_=MLP(\n",
       "    (dense0): Linear(in_features=20, out_features=10, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (dense1): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (output): Linear(in_features=10, out_features=2, bias=True)\n",
       "  ),\n",
       "),\n",
       "             param_grid={&#x27;lr&#x27;: [0.05, 0.1], &#x27;module__dropout&#x27;: [0, 0.5],\n",
       "                         &#x27;module__num_units&#x27;: [10, 20]},\n",
       "             refit=False, scoring=&#x27;accuracy&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=&lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[initialized](\n",
       "  module_=MLP(\n",
       "    (dense0): Linear(in_features=20, out_features=10, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (dense1): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (output): Linear(in_features=10, out_features=2, bias=True)\n",
       "  ),\n",
       "),\n",
       "             param_grid={&#x27;lr&#x27;: [0.05, 0.1], &#x27;module__dropout&#x27;: [0, 0.5],\n",
       "                         &#x27;module__num_units&#x27;: [10, 20]},\n",
       "             refit=False, scoring=&#x27;accuracy&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: NeuralNetClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[initialized](\n",
       "  module_=MLP(\n",
       "    (dense0): Linear(in_features=20, out_features=10, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (dense1): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (output): Linear(in_features=10, out_features=2, bias=True)\n",
       "  ),\n",
       ")</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NeuralNetClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[initialized](\n",
       "  module_=MLP(\n",
       "    (dense0): Linear(in_features=20, out_features=10, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (dense1): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (output): Linear(in_features=10, out_features=2, bias=True)\n",
       "  ),\n",
       ")</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=MLP(\n",
       "    (dense0): Linear(in_features=20, out_features=10, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (dense1): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (output): Linear(in_features=10, out_features=2, bias=True)\n",
       "  ),\n",
       "),\n",
       "             param_grid={'lr': [0.05, 0.1], 'module__dropout': [0, 0.5],\n",
       "                         'module__num_units': [10, 20]},\n",
       "             refit=False, scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e621a65b-7d8d-42ac-ae48-1ebf20249b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7530134925344506 {'lr': 0.1, 'module__dropout': 0, 'module__num_units': 20}\n"
     ]
    }
   ],
   "source": [
    "print(gs.best_score_, gs.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
